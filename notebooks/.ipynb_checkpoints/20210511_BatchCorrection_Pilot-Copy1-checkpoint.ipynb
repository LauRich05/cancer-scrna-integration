{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pilot Analysis: Batch Correction\n",
    "*L.Richards*  \n",
    "*2020-05-22*  \n",
    "*/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection*  \n",
    "\n",
    "---\n",
    "\n",
    "Based on investigating clustering patterns in biological replicates, it looks like we might have some technical batch effects between samples. There were some shifts between the biological replicates acrss all cell types, not just the malignant fraction where we might expect there to be some. So we need to at least try some form of batch correction. \n",
    "\n",
    "\n",
    "** Conclusion:** STACAS is the best, but most time and memory expensive to run (needed 120G to run on 33k cell dataset...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.0 Generate data cohort (H4H)\n",
    "---\n",
    "\n",
    "Lets merge 3 pairs together, that way we have a good mix of biological replicates, multiple samples from the same patient and  samples from different patients. This shouldddd help us understand if the algorithms are over or under correcting the data (but most likely over correcting...)\n",
    "\n",
    "/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/input-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "\n",
    "setwd(\"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection\")\n",
    "source(\"~/github/oicr-brain-tri-gbm/src/scRNA_helper_functions.r\")\n",
    "\n",
    "data.path <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/remove-doublets/seurat_objs/patients\"\n",
    "\n",
    "objects <- c(\"B_P.GBM593.1_P.GBM593.2_R.GBM898_Seurat.rds\", #LGG oligoastrocytoma\n",
    "             \"C_P.GBM577.1_P.GBM577.2_R.GBM625_Seurat.rds\", # GBM\n",
    "             \"F_P.GBM620_R.GBM691_Seurat.rds\" # GBM\n",
    "            )\n",
    "\n",
    "# read in seurat objects into a list\n",
    "seurats <- list()\n",
    "for (i in 1:length(objects)){\n",
    "    \n",
    "    seurats[[i]] <- readRDS(paste0(data.path, \"/\", objects[i])) \n",
    "    \n",
    "}\n",
    "\n",
    "# merge seurat objects together\n",
    "# new cohort size is 35,549 nuclei\n",
    "seurats <- merge(seurats[[1]], y = c(seurats[[2]], seurats[[3]]))\n",
    "\n",
    "# cluster merged data\n",
    "seurats <- quickCluster(seurats,\n",
    "                        normalize = TRUE,\n",
    "                        vars.to.regress = NULL,\n",
    "                        #k.param = 20,\n",
    "                        dims = 20, # max dims 1:dims\n",
    "                        n.vargenes = 2000,\n",
    "                        min.resolution = 2.11,\n",
    "                        max.resolution = 2.11,\n",
    "                        n.resolution = 1, #how many resolutions to cluster over\n",
    "                        verbose = FALSE,\n",
    "                        pc.calc = 75, # how many PCs to calculate\n",
    "                        pca.genes = \"var\" # accepts \"all\" or \"var\"\n",
    "                       )\n",
    "\n",
    "# plot data\n",
    "pdf(\"Pairs_B.C.F_NoBatchCorrection.pdf\", width = 18, height = 5)\n",
    "DimPlot(dat, \n",
    "        group.by = c(\"SampleID\", \"PairID\", \"SingleR_CollapsedLabels\"),\n",
    "        ncol = 3\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "# save data\n",
    "saveRDS(seurats, file = \"./input-data/Pairs_B.C.F_Seurat.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.0 Run Batch Correction Tools (H4H)\n",
    "---\n",
    "\n",
    "Lets start with the easy ones that have Seurat wrappers, and bonus that they are also some of the top performing algorithms for batch correction when samples have different populations of cells -- which is key for not erasing biological patterns that are unique to each tumour's malignant fraction. \n",
    "\n",
    "https://github.com/satijalab/seurat-wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "library(SeuratWrappers)\n",
    "library(rliger)\n",
    "library(conos)\n",
    "library(batchelor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.1 LIGER (not working because liger package name changed)\n",
    "---\n",
    "\n",
    "https://github.com/welch-lab/liger  \n",
    "http://htmlpreview.github.io/?https://github.com/satijalab/seurat-wrappers/blob/master/docs/liger.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/input-data/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_Seurat.rds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run liger\n",
    "dat <- NormalizeData(dat)\n",
    "dat  <- FindVariableFeatures(dat , nfeatures = 2000)\n",
    "dat  <- ScaleData(dat, split.by = \"SampleID\", do.center = FALSE)\n",
    "dat  <- RunOptimizeALS(dat, k = 20, lambda = 5, split.by = \"SampleID\")\n",
    "dat  <- RunQuantileNorm(dat, split.by = \"SampleID\")\n",
    "\n",
    "# You can optionally perform Louvain clustering (`FindNeighbors` and `FindClusters`) after\n",
    "# `RunQuantileNorm` according to your needs\n",
    "dat <- FindNeighbors(dat, reduction = \"iNMF\", dims = 1:20)\n",
    "dat <- FindClusters(dat, resolution = 0.3)\n",
    "\n",
    "# Dimensional reduction and plotting\n",
    "dat <- RunUMAP(dat, dims = 1:ncol(dat[[\"iNMF\"]]), reduction = \"iNMF\")\n",
    "\n",
    "# plot data\n",
    "pdf(\"Pairs_B.C.F_LIGER.pdf\", width = 12.4, height = 6)\n",
    "DimPlot(dat, \n",
    "        group.by = c(\"SampleID\", \"SingleR_CollapsedLabel\"),\n",
    "        ncol = 2\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "# save data\n",
    "saveRDS(dat, file = \"./input-data/Pairs_B.C.F_Seurat_Liger.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.2 Conos\n",
    "---\n",
    "\n",
    "http://htmlpreview.github.io/?https://github.com/satijalab/seurat-wrappers/blob/master/docs/conos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/input-data/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_Seurat.rds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split up data and normalize\n",
    "dat.panel <- SplitObject(dat, split.by = \"SampleID\")\n",
    "\n",
    "for (i in 1:length(dat.panel)) {\n",
    "    dat.panel[[i]] <- NormalizeData(dat.panel[[i]]) %>% FindVariableFeatures() %>% ScaleData() %>% \n",
    "        RunPCA(verbose = FALSE)\n",
    "}\n",
    "\n",
    "# run Conos\n",
    "dat.con <- Conos$new(dat.panel)\n",
    "dat.con$buildGraph(k = 15, \n",
    "                   k.self = 5, \n",
    "                   space = \"PCA\", \n",
    "                   ncomps = 30, \n",
    "                   n.odgenes = 2000, \n",
    "                   matching.method = \"mNN\", \n",
    "                   metric = \"angular\", \n",
    "                   score.component.variance = TRUE, \n",
    "                   verbose = TRUE\n",
    "                  )\n",
    "dat.con$findCommunities()\n",
    "dat.con$embedGraph()\n",
    "dat <- as.Seurat(dat.con)\n",
    "\n",
    "# plot results\n",
    "pdf(\"Pairs_B.C.F_Conos.pdf\", width = 18, height = 5)\n",
    "DimPlot(dat, \n",
    "        reduction = \"largeVis\", \n",
    "        group.by = c(\"SampleID\", \"PairID\", \"SingleR_CollapsedLabels\"),\n",
    "        ncol = 3\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "# save results\n",
    "saveRDS(dat, file = \"./Pairs_B.C.F_Seurat_Conos.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.3 fastMNN\n",
    "---\n",
    "\n",
    "http://htmlpreview.github.io/?https://github.com/satijalab/seurat-wrappers/blob/master/docs/fast_mnn.html\n",
    "\n",
    "module load R/3.6.1\n",
    "\n",
    "This is being a pain because the objects are saved using Seurat v4 whcih need SeuratObject to run...but cant install in R/v3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# module load R/4.0.0\n",
    "\n",
    "library(Seurat)\n",
    "\n",
    "# load data\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/input-data/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_Seurat.rds\"))\n",
    "\n",
    "# ouput just the counts and metadata \n",
    "counts <- dat@assays$RNA@counts\n",
    "meta <- dat@meta.data\n",
    "dat <- list(counts, meta)\n",
    "saveRDS(dat, file = \"Pairs_B.C.F_counts_meta.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# module load R/3.6.1\n",
    "\n",
    "library(Seurat)\n",
    "library(batchelor)\n",
    "library(SeuratWrappers)\n",
    "\n",
    "# load data\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_counts_meta.rds\"))\n",
    "dat <- CreateSeuratObject(counts = dat[[1]],\n",
    "                          meta.data = dat[[2]],\n",
    "                         )\n",
    "\n",
    "# run fastmnn\n",
    "dat <- NormalizeData(dat)\n",
    "dat <- FindVariableFeatures(dat, nfeatures = 2000)\n",
    "dat <- RunFastMNN(object.list = SplitObject(dat, split.by = \"SampleID\"))\n",
    "dat <- RunUMAP(dat, reduction = \"mnn\", dims = 1:30)\n",
    "dat <- FindNeighbors(dat, reduction = \"mnn\", dims = 1:30)\n",
    "dat <- FindClusters(dat)\n",
    "\n",
    "# plot results\n",
    "pdf(\"Pairs_B.C.F_fastmnn.pdf\", width = 18, height = 5)\n",
    "DimPlot(dat, \n",
    "        group.by = c(\"SampleID\", \"PairID\", \"SingleR_CollapsedLabels\"),\n",
    "        ncol = 3\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "# save results\n",
    "saveRDS(dat, file = \"./Pairs_B.C.F_Seurat_fastmnn.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.4 Harmony\n",
    "---\n",
    "\n",
    "https://github.com/satijalab/seurat-wrappers/blob/master/docs/harmony.md\n",
    "\n",
    "module load R/3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# module load R/3.6.1\n",
    "\n",
    "library(Seurat)\n",
    "library(harmony)\n",
    "library(SeuratWrappers)\n",
    "\n",
    "# load data\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_counts_meta.rds\"))\n",
    "dat <- CreateSeuratObject(counts = dat[[1]],\n",
    "                          meta.data = dat[[2]],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run harmony correction\n",
    "dat <- NormalizeData(dat) %>% FindVariableFeatures() %>% ScaleData() %>% RunPCA(verbose = FALSE)\n",
    "dat <- RunHarmony(dat, group.by.vars = \"SampleID\")\n",
    "dat <- RunUMAP(dat, reduction = \"harmony\", dims = 1:30)\n",
    "dat <- FindNeighbors(dat, reduction = \"harmony\", dims = 1:30) %>% FindClusters()\n",
    "\n",
    "# plot results\n",
    "#pdf(\"Pairs_B.C.F_harmony.pdf\", width = 18, height = 5)\n",
    "DimPlot(dat, \n",
    "        group.by = c(\"SampleID\", \"PairID\", \"SingleR_CollapsedLabels\"),\n",
    "        ncol = 3\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "# save results\n",
    "saveRDS(dat, file = \"./Pairs_B.C.F_Seurat_harmony.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.5 STACAS\n",
    "---\n",
    "\n",
    "https://carmonalab.github.io/STACAS/tutorial.html\n",
    "\n",
    "module load R/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "library(STACAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/input-data/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_Seurat.rds\"))\n",
    "\n",
    "# split by sample\n",
    "ref.list <- SplitObject(dat, split.by = \"SampleID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var.genes.n <- 2000 # multipled by 2 below (previously was 1000)\n",
    "var.genes.integrated.n <- 2000\n",
    "ndim <- 20\n",
    "dist.pct <- 0.8\n",
    "\n",
    "for (i in 1:length(ref.list)) {\n",
    "    \n",
    "    ref.list[[i]] <- NormalizeData(ref.list[[i]], verbose = FALSE)\n",
    "    \n",
    "    ref.list[[i]] <- FindVariableFeatures(ref.list[[i]], \n",
    "                                          selection.method = \"vst\", \n",
    "                                          nfeatures = var.genes.n*2, \n",
    "                                          verbose = FALSE\n",
    "                                         )\n",
    "    \n",
    "    mito.genes <- grep(pattern = \"^MT-\", rownames(ref.list[[i]]), value = TRUE)\n",
    "    ribo.genes <- grep(pattern = \"^RP[LS]\", rownames(ref.list[[i]]), value = TRUE)\n",
    "    \n",
    "    #ref.list[[i]]@assays$RNA@var.features <- setdiff(ref.list[[i]]@assays$RNA@var.features, cellCycle.symbol)\n",
    "    ref.list[[i]]@assays$RNA@var.features <- setdiff(ref.list[[i]]@assays$RNA@var.features, mito.genes)\n",
    "    ref.list[[i]]@assays$RNA@var.features <- setdiff(ref.list[[i]]@assays$RNA@var.features, ribo.genes)\n",
    "    ref.list[[i]]@assays$RNA@var.features <- head( ref.list[[i]]@assays$RNA@var.features, var.genes.n)\n",
    "    \n",
    "}\n",
    "\n",
    "ref.anchors <- FindAnchors.STACAS(ref.list, \n",
    "                                  dims=1:ndim, \n",
    "                                  anchor.features=var.genes.integrated.n\n",
    "                                 )\n",
    "\n",
    "ref.anchors.filtered <- FilterAnchors.STACAS(ref.anchors,\n",
    "                                             dist.pct = dist.pct\n",
    "                                            )\n",
    "\n",
    "all.genes <- row.names(ref.list[[1]])\n",
    "\n",
    "for (i in 2:length(ref.list)) {\n",
    "   \n",
    "    all.genes <- intersect(all.genes, row.names(ref.list[[i]]))\n",
    "    \n",
    "}\n",
    "\n",
    "mySampleTree <- SampleTree.STACAS(ref.anchors.filtered)\n",
    "print(mySampleTree)\n",
    "\n",
    "\n",
    "ref.integrated <- IntegrateData(anchorset=ref.anchors.filtered, \n",
    "                                dims=1:ndim, \n",
    "                                features.to.integrate=all.genes,\n",
    "                                sample.tree=mySampleTree, \n",
    "                                preserve.order=T\n",
    "                               )\n",
    "\n",
    "\n",
    "# process and cluster\n",
    "ref.integrated <- ScaleData(ref.integrated, verbose = TRUE)\n",
    "ref.integrated <- RunPCA(ref.integrated, \n",
    "                         features = ref.integrated@assays$integrated@var.features,\n",
    "                         ndims.print = 1:5, \n",
    "                         nfeatures.print = 5\n",
    "                        )\n",
    "ref.integrated <- RunUMAP(ref.integrated, \n",
    "                          reduction = \"pca\", \n",
    "                          dims = 1:ndim, \n",
    "                          seed.use=123, \n",
    "                          n.neighbors = 30, \n",
    "                          min.dist=0.3\n",
    "                         )\n",
    "\n",
    "# plot results of integration\n",
    "pdf(\"Pairs_B.C.F_stacas.pdf\", width = 18, height = 5)\n",
    "DimPlot(ref.integrated, \n",
    "        reduction = \"umap\",\n",
    "        group.by = c(\"SampleID\", \"PairID\", \"SingleR_CollapsedLabels\"),\n",
    "        ncol = 3\n",
    "       )\n",
    "dev.off()\n",
    "\n",
    "# save results\n",
    "saveRDS(ref.integrated, file = \"./Pairs_B.C.F_Seurat_stacas.rds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2.6 Reciprocal PCA (RPCA)\n",
    "---\n",
    "\n",
    "\n",
    "module load R/4\n",
    "https://satijalab.org/seurat/articles/integration_rpca.html\n",
    "\n",
    "RPCA seems like it will be a better fit for cancer samples, as it is more conservative, you can adjust the strength of the integration and is recommneded over CCA when  a substantial fraction of cells in one dataset have no matching type in the other -- perfect for a mixed pathologt cohrot. If produces similar results to STACAS, this could be preferable since it likely runs much faster. \n",
    "\n",
    "Run over a range of k from 5 (least conservative) to 20 (more integration) to see which gives the best results. \n",
    "\n",
    ">\"In this vignette, we present a slightly modified workflow for the integration of scRNA-seq datasets. Instead of utilizing canonical correlation analysis (‘CCA’) to identify anchors, we instead utilize reciprocal PCA (‘RPCA’). When determining anchors between any two datasets using RPCA, we project each dataset into the others PCA space and constrain the anchors by the same mutual neighborhood requirement. The commands for both workflows are largely identical, but the two methods may be applied in different context.\n",
    "\n",
    "> By identifying shared sources of variation between datasets, CCA is well-suited for identifying anchors when cell types are conserved, but there are very substantial differences in gene expression across experiments. CCA-based integration therefore enables integrative analysis when experimental conditions or disease states introduce very strong expression shifts, or when integrating datasets across modalities and species. However, CCA-based integration may also lead to overcorrection, especially when a large proportion of cells are non-overlapping across datasets.\n",
    "\n",
    "> RPCA-based integration runs significantly faster, and also represents a more conservative approach where cells in different biological states are less likely to ‘align’ after integration. We therefore,recommend RPCA during integrative analysis where: A substantial fraction of cells in one dataset have no matching type in the other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(Seurat)\n",
    "\n",
    "# load dataset\n",
    "input <- \"/cluster/projects/pughlab/projects/OICR_Brain_NucSeq/GBM/analysis/BatchCorrection/input-data/\"\n",
    "dat <- readRDS(paste0(input, \"Pairs_B.C.F_Seurat.rds\"))\n",
    "\n",
    "# split up dataset by sample\n",
    "dat.list <- SplitObject(dat, split.by = \"SampleID\")\n",
    "\n",
    "# normalize and identify variable features for each dataset independently\n",
    "dat.list <- lapply(X = dat.list, FUN = function(x) {\n",
    "    x <- NormalizeData(x)\n",
    "    x <- FindVariableFeatures(x, selection.method = \"vst\", nfeatures = 2000)\n",
    "})\n",
    "\n",
    "# select features that are repeatedly variable across datasets for integration run PCA on each\n",
    "# dataset using these features\n",
    "features <- SelectIntegrationFeatures(object.list = dat.list) #2000\n",
    "dat.list <- lapply(X = dat.list, FUN = function(x) {\n",
    "    x <- ScaleData(x, features = features, verbose = FALSE)\n",
    "    x <- RunPCA(x, features = features, verbose = FALSE)\n",
    "})\n",
    "\n",
    "# perform integration\n",
    "# The results show that rpca-based integration is more conservative, \n",
    "# You can increase the strength of alignment by increasing the \n",
    "#k.anchor parameter, which is set to 5 by default. \n",
    "#Increasing this parameter to 20 will assist in aligning these \n",
    "#populations.\n",
    "\n",
    "# define range of k.anchors\n",
    "# k.anchors = How many neighbors (k) to use when picking anchors\n",
    "k.anchors <- c(5, 10, 15, 20)\n",
    "\n",
    "for (i in 2:length(k.anchors)){\n",
    "    \n",
    "    dat.anchors <- FindIntegrationAnchors(object.list = dat.list, \n",
    "                                          anchor.features = features, \n",
    "                                          reduction = \"rpca\",\n",
    "                                          k.anchor = k.anchors[i]\n",
    "                                         )\n",
    "\n",
    "    # this command creates an 'integrated' data assay\n",
    "    dat.combined <- IntegrateData(anchorset = dat.anchors)\n",
    "\n",
    "    # specify that we will perform downstream analysis on the corrected data note that the original\n",
    "    # unmodified data still resides in the 'RNA' assay\n",
    "    DefaultAssay(dat.combined) <- \"integrated\"\n",
    "\n",
    "    # Run the standard workflow for visualization and clustering\n",
    "    dat.combined <- ScaleData(dat.combined, verbose = FALSE)\n",
    "    dat.combined <- RunPCA(dat.combined, npcs = 30, verbose = FALSE)\n",
    "    dat.combined <- RunUMAP(dat.combined, reduction = \"pca\", dims = 1:30)\n",
    "    dat.combined <- FindNeighbors(dat.combined, reduction = \"pca\", dims = 1:30)\n",
    "    dat.combined <- FindClusters(dat.combined, resolution = 0.5)\n",
    "\n",
    "    # Visualization of results \n",
    "    # plot results of integration\n",
    "    plot.name <- paste0(\"Pairs_B.C.F_RPCA_k\", k.anchors[i], \".pdf\")\n",
    "    pdf(plot.name, width = 18, height = 5)\n",
    "    DimPlot(dat.combined, \n",
    "            reduction = \"umap\",\n",
    "            group.by = c(\"SampleID\", \"PairID\", \"SingleR_CollapsedLabels\"),\n",
    "            ncol = 3\n",
    "           )\n",
    "    dev.off()\n",
    "\n",
    "    # save results\n",
    "    save.name <- paste0(\"Pairs_B.C.F_RPCA_k\", k.anchors[i], \"_Seurat.rds\")\n",
    "    saveRDS(dat.combined, file = save.name)\n",
    "    \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
